{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIcR4TwS2dCQ",
        "outputId": "0169e7b5-3dd2-4396-aab5-48198dc5ec9c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MbYMajWl2rwz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import sklearn\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Input,Dense,Conv2D,concatenate,Dropout,LSTM\n",
        "from keras import Model\n",
        "from tensorflow.keras import activations\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import nltk.translate.bleu_score as bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nbciUZ2P2whW"
      },
      "outputs": [],
      "source": [
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPPi42mKz5tO",
        "outputId": "4adb0a54-89b5-4bd4-f986-f73f79f30734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "image_shape= (224,224,3)\n",
        "image_input= Input(shape=(224,224,3))\n",
        "base=DenseNet121(include_top=False,input_tensor=image_input,input_shape=image_shape,pooling=\"avg\")\n",
        "pred=Dense(14,\"sigmoid\")(base.output)\n",
        "\n",
        "chexnet_model=Model(inputs=base.input,outputs=pred)\n",
        "chexnet_model.load_weights(\"chexnet_weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ii4kQiN6z8-j"
      },
      "outputs": [],
      "source": [
        "final_chexnet_model=Model(inputs=chexnet_model.inputs,outputs=chexnet_model.layers[-2].output,name=\"Chexnet_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PGzuXIF5zjX3"
      },
      "outputs": [],
      "source": [
        "image_1= Input(shape=(224,224,3),name=\"image_1_features\")\n",
        "image_2= Input(shape=(224,224,3),name=\"image_2_features\")\n",
        "image_1_out=final_chexnet_model(image_1)\n",
        "image_2_out=final_chexnet_model(image_2)\n",
        "conc=concatenate((image_1_out,image_2_out),axis=-1,name=\"final_image_features\")\n",
        "feature_extraction_model=Model(inputs=[image_1,image_2],outputs=conc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sxR4OaEDv7g7"
      },
      "outputs": [],
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='auto')\n",
        "def maskedLoss(y_true, y_pred):\n",
        "    #getting mask value\n",
        "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
        "\n",
        "    #calculating the loss\n",
        "    loss_ = loss_function(y_true, y_pred)\n",
        "\n",
        "    #converting mask dtype to loss_ dtype\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "\n",
        "    #applying the mask to loss\n",
        "    loss_ = loss_*mask\n",
        "\n",
        "    #getting mean over all the values\n",
        "    loss_ = tf.reduce_mean(loss_)\n",
        "    return loss_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srtnybyv21PO"
      },
      "source": [
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/encoder_decoder_epoch_30(buff)_200.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1n5SJ6tShL5",
        "outputId": "b147a73d-1783-4702-c6f0-106ccbe58613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3056, 5)\n",
            "(764, 5)\n"
          ]
        }
      ],
      "source": [
        "#first we split the data set into train and test data sets\n",
        "data=pd.read_csv(\"data.csv\")\n",
        "\n",
        "train,test=train_test_split(data,test_size=0.2,random_state=1,shuffle=True)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NzDcesVT0oiA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def image_feature_extraction(image1,image2):\n",
        "\n",
        "\n",
        "  image_1 = Image.open(image1)\n",
        "\n",
        "  image_1= np.asarray(image_1.convert(\"RGB\"))\n",
        "\n",
        "\n",
        "  image_2=Image.open(image2)\n",
        "  image_2 = np.asarray(image_2.convert(\"RGB\"))\n",
        "\n",
        "    #normalize the values of the image\n",
        "  image_1=image_1/255\n",
        "  image_2=image_2/255\n",
        "\n",
        "    #resize all image into (224,224)\n",
        "  image_1 = cv2.resize(image_1,(224,224))\n",
        "  image_2 = cv2.resize(image_2,(224,224))\n",
        "\n",
        "  image_1= np.expand_dims(image_1, axis=0)\n",
        "  image_2= np.expand_dims(image_2, axis=0)\n",
        "\n",
        "    #now we have read two image per patient. this is goven to the chexnet model for feature extraction\n",
        "\n",
        "  image_feature=feature_extraction_model([image_1,image_2])\n",
        "\n",
        "  return image_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsJKnxnHTe-7",
        "outputId": "c2d0d9e3-fd67-46d3-d337-17d03df6e5b0"
      },
      "outputs": [],
      "source": [
        "#train_features=[]\n",
        "#test_features=[]\n",
        "#for row in tqdm(range(train.shape[0])):\n",
        "#  image_1=train.iloc[row][\"image1\"]\n",
        "#  image_2=train.iloc[row][\"image2\"]\n",
        "#  train_features.append(image_feature_extraction(image_1,image_2))\n",
        "#print(\"DONE\")\n",
        "#for row in tqdm(range(test.shape[0])):\n",
        "#  image_1=test.iloc[row][\"image1\"]\n",
        "#  image_2=test.iloc[row][\"image2\"]\n",
        "#  test_features.append(image_feature_extraction(image_1,image_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2I_fXZ2TfSz",
        "outputId": "099c55d4-4121-4ea0-9f62-efbb57c067c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3056, 1, 2048)\n"
          ]
        }
      ],
      "source": [
        "#train[\"image_features\"]=train_features\n",
        "#test[\"image_features\"]=test_features\n",
        "\n",
        "#np.savez(\"train_image_features\",train_features)\n",
        "#np.savez(\"test_image_features\",test_features)\n",
        "\n",
        "train_features=np.load(\"train_image_features.npz\")\n",
        "train_features=train_features['arr_0']\n",
        "test_features=np.load(\"test_image_features.npz\")\n",
        "test_features=test_features['arr_0']\n",
        "print(train_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TQa3SJVsTtPD"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_report=[\" \"+text+\" \" for text in train[\"report\"].values]\n",
        "\n",
        "test_report=[\" \" +text+\" \" for text in test[\"report\"].values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QYgJRFvv0UwL"
      },
      "outputs": [],
      "source": [
        "max_len=80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5MqGrMSv0zcW"
      },
      "outputs": [],
      "source": [
        "#Obtaining the text embeddings of the report\n",
        "# we use the tensorflow tokenizer to convert the text into tokens\n",
        "#we also pad the sequences to a length 300 which is around the 90th percentile of the lengths of the report\n",
        "\n",
        "token=tf.keras.preprocessing.text.Tokenizer(filters='' )\n",
        "token.fit_on_texts(train_report)\n",
        "vocab_size=len(token.word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdGXNSjt-3ua",
        "outputId": "2d567996-e04a-44cd-b21e-dbebc105b418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2011/2011 [00:00<00:00, 201114.58it/s]\n"
          ]
        }
      ],
      "source": [
        "embeddings_index=dict()\n",
        "f = open('glove.6B.300d.txt',encoding='utf-8')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print(\"Done\")\n",
        "# create a weight matrix for words in training docs\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tqdm(token.word_index.items()):\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DLBe1oIgUK4n"
      },
      "outputs": [],
      "source": [
        "max_len=30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNSHbmccUD66",
        "outputId": "04070576-e3e4-4d44-fd8b-57f7d092f0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None, 30)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 30, 300)              603600    ['text[0][0]']                \n",
            "                                                                                                  \n",
            " LSTM1 (LSTM)                (None, 30, 256)              570368    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " Images (InputLayer)         [(None, 2048)]               0         []                            \n",
            "                                                                                                  \n",
            " LSTM2 (LSTM)                (None, 512)                  1574912   ['LSTM1[0][0]']               \n",
            "                                                                                                  \n",
            " enc_dense (Dense)           (None, 512)                  1049088   ['Images[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 512)                  0         ['LSTM2[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 512)                  0         ['enc_dense[0][0]',           \n",
            "                                                                     'dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 512)                  262656    ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 512)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2012)                 1032156   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5092780 (19.43 MB)\n",
            "Trainable params: 4489180 (17.12 MB)\n",
            "Non-trainable params: 603600 (2.30 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#constructing the encoder-decoder model\n",
        "\n",
        "#encoder model\n",
        "input_1=Input(shape=(2048),name=\"Images\")\n",
        "encoder_out=Dense(512,activation=\"relu\",name=\"enc_dense\")(input_1)\n",
        "\n",
        "\n",
        "#decoder model\n",
        "input_text=Input(shape=(max_len),name=\"text\")\n",
        "\n",
        "embedding_out=tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=300,input_length=max_len,mask_zero=True,trainable=False,weights=[embedding_matrix])(input_text)\n",
        "\n",
        "lstm_out= LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
        "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
        "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
        "            bias_initializer=tf.keras.initializers.zeros(), return_sequences=True, name=\"LSTM1\")(embedding_out)\n",
        "\n",
        "lstm_out= LSTM(units=512, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
        "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
        "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
        "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")(lstm_out)\n",
        "\n",
        "x=Dropout(0.5)(lstm_out)\n",
        "add=tf.keras.layers.Add()([encoder_out, x])\n",
        "\n",
        "x=Dense(512,kernel_initializer=tf.keras.initializers.he_normal(seed =1),activation=\"relu\")(add)\n",
        "\n",
        "x1=Dropout(0.25)(x)\n",
        "\n",
        "x1=Dense(vocab_size,activation=\"softmax\")(x1)\n",
        "#encoder_decoder_model\n",
        "encoder_decoder=Model(inputs=[input_1,input_text],outputs=x1)\n",
        "encoder_decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wvkqchlP0SfJ"
      },
      "outputs": [],
      "source": [
        "def evaluate(image1,image2):\n",
        "    #Given the images from test data, we extract the bottleneck features from chexnet model\n",
        "    image_features = image_feature_extraction(image1,image2)\n",
        "    output_report=\"\"\n",
        "\n",
        "    #first word for the report is given as\n",
        "    inp= \"\"\n",
        "\n",
        "    image_features=tf.reshape(image_features,shape=(-1,image_features.shape[-1]))\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(max_len):\n",
        "        #we find the list of tokens for the input word (already available words)\n",
        "        list_of_tokens = [token.word_index[w] for w in inp.split()]\n",
        "\n",
        "        #padd the available tokens to max_len\n",
        "        input_padded = tf.keras.preprocessing.sequence.pad_sequences([list_of_tokens],max_len, padding='post')\n",
        "\n",
        "        #we pass the image_features and the padded input to the enocoder decoder model and predict the next token\n",
        "        predictions = encoder_decoder.predict([image_features,input_padded])\n",
        "\n",
        "        #find the corresponding word and attach to the result\n",
        "        arg = np.argmax(predictions[0])\n",
        "\n",
        "        if token.index_word[arg]==\"\":\n",
        "\n",
        "          output_report+=token.index_word[arg]+\" \"\n",
        "          break\n",
        "        else:\n",
        "\n",
        "            output_report+=token.index_word[arg]+\" \"\n",
        "            inp+= ' ' + token.index_word[arg]\n",
        "\n",
        "\n",
        "    return output_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "h10WBwEzS-kL"
      },
      "outputs": [],
      "source": [
        "model_path = \"encoder_decoder_epoch_30(buff)_200.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWQ01FiYuWwP",
        "outputId": "d9cbab2c-1392-4c4b-ff66-8d704bd02ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None, 30)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 30, 300)              603600    ['text[0][0]']                \n",
            "                                                                                                  \n",
            " LSTM1 (LSTM)                (None, 30, 256)              570368    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " Images (InputLayer)         [(None, 2048)]               0         []                            \n",
            "                                                                                                  \n",
            " LSTM2 (LSTM)                (None, 512)                  1574912   ['LSTM1[0][0]']               \n",
            "                                                                                                  \n",
            " enc_dense (Dense)           (None, 512)                  1049088   ['Images[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 512)                  0         ['LSTM2[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 512)                  0         ['enc_dense[0][0]',           \n",
            "                                                                     'dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 512)                  262656    ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 512)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2012)                 1032156   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5092780 (19.43 MB)\n",
            "Trainable params: 4489180 (17.12 MB)\n",
            "Non-trainable params: 603600 (2.30 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "encoder_decoder = tf.keras.models.load_model(model_path, custom_objects={\"maskedLoss\": maskedLoss})\n",
        "\n",
        "# Display the model summary\n",
        "encoder_decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HsBJASlc1F27"
      },
      "outputs": [],
      "source": [
        "# Provide the path to the single X-ray image\n",
        "image_path = root_path + \"\\data\\images\\CXR3724_IM-1860-1001_Report_pnuemo.png\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED REPORT: Heart size normal. Multiple scattered small nodules throughout the chest. These most represent calcified small granulomas. Low film demonstrate these are probably calcified. \n"
          ]
        }
      ],
      "source": [
        "def truncate_incomplete_sentences(text):\n",
        "    # Split the text into sentences\n",
        "    sentences = text.split('.')\n",
        "    # print(\"Sentences:\", sentences)  # Print the sentences for debugging\n",
        "    \n",
        "    # Check if the last sentence is incomplete\n",
        "    if not sentences[-1].strip().endswith('.'):\n",
        "        # Find the index of the last occurrence of '.'\n",
        "        last_period_index = text.rfind('.')\n",
        "        # print(\"Last period index:\", last_period_index)\n",
        "        \n",
        "        # Truncate the text before the last occurrence of '.'\n",
        "        truncated_text = text[:last_period_index + 1]\n",
        "        # print(\"Truncated text:\", truncated_text)\n",
        "        \n",
        "        # Capitalize the start of every sentence\n",
        "        truncated_text = '. '.join(sentence.strip().capitalize() for sentence in truncated_text.split('.'))\n",
        "        # print(\"Capitalized text:\", truncated_text)\n",
        "        \n",
        "        return truncated_text\n",
        "    else:\n",
        "        # If the last sentence is complete or it's the only sentence, return the original text\n",
        "        return text\n",
        "\n",
        "# Example usage\n",
        "text = \"heart size normal. multiple scattered small nodules throughout the chest. these most represent calcified small granulomas. low film demonstrate these are probably calcified. there are calcified granulomas within the right\"\n",
        "truncated_report = truncate_incomplete_sentences(text)\n",
        "print(\"GENERATED REPORT:\", truncated_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4or05Vz4fr5",
        "outputId": "fa8270cb-778b-40c1-9b6a-e63fd9b52e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "result as: heart size normal. multiple scattered small nodules throughout the chest. these most represent calcified small granulomas. low film demonstrate these are probably calcified. there are calcified granulomas within the right \n",
            "GENERATED REPORT:  Heart size normal. Multiple scattered small nodules throughout the chest. These most represent calcified small granulomas. Low film demonstrate these are probably calcified. \n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "#img = preprocess_image(image_path)\n",
        "result=evaluate(image_path,image_path)\n",
        "# print(\"result as:\",result)\n",
        "truncated_report = truncate_incomplete_sentences(result)\n",
        "  #actual=test_report[i]\n",
        "  #print(\"ACTUAL REPORT: \",actual)\n",
        "print(\"GENERATED REPORT: \",truncated_report)\n",
        "print(\"*\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
